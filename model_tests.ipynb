{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-27 21:52:25.915769: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import dataclasses as dcls\n",
    "import functools\n",
    "import math\n",
    "import os\n",
    "import string\n",
    "from typing import Tuple, List, Dict, Any, Optional, Callable\n",
    "\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "tf.__version__, tf.keras.__version__, tfa.__version__\n",
    "\n",
    "from sds.model.params import ScaledParams\n",
    "from sds.utils.utils import compose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOMENTUM = 0.997\n",
    "EPSILON = 1e-4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-27 21:52:28.547792: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-01-27 21:52:28.549043: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-01-27 21:52:28.571628: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2022-01-27 21:52:28.571663: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: train\n",
      "2022-01-27 21:52:28.571672: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: train\n",
      "2022-01-27 21:52:28.571775: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 470.86.0\n",
      "2022-01-27 21:52:28.571801: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 470.86.0\n",
      "2022-01-27 21:52:28.571809: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 470.86.0\n",
      "2022-01-27 21:52:28.572170: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-27 21:52:28.572591: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "phi = 0\n",
    "num_classes = 20\n",
    "freeze_bn = True\n",
    "params = ScaledParams(phi)\n",
    "image_input = tf.keras.Input(params.input_shape)\n",
    "_, bb_feature_maps = params.backbone_class(input_tensor=image_input, freeze_bn=freeze_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'phi': 0, 'input_size': 512, 'input_shape': (512, 512, 3), 'bifpn_width': 64, 'bifpn_depth': 3, 'subnet_width': 64, 'subnet_depth': 3, 'subnet_num_iteration_steps': 1, 'num_groups_gn': 4, 'backbone_class': <function EfficientNetB0 at 0x7efe7fca84c0>}\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 256, 256, 16), dtype=tf.float32, name=None), name='block1b_project_bn/FusedBatchNormV3:0', description=\"created by layer 'block1b_project_bn'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 24), dtype=tf.float32, name=None), name='block2c_add/add:0', description=\"created by layer 'block2c_add'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name=None), name='block3c_add/add:0', description=\"created by layer 'block3c_add'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name=None), name='block5d_add/add:0', description=\"created by layer 'block5d_add'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name=None), name='block7b_project_bn/FusedBatchNormV3:0', description=\"created by layer 'block7b_project_bn'\")\n"
     ]
    }
   ],
   "source": [
    "print(params.__dict__)\n",
    "for bb_feature_map in bb_feature_maps:\n",
    "    print(bb_feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefixer(prefix: str = ''):\n",
    "    if not prefix:\n",
    "        return lambda name: name\n",
    "    return lambda name: f'{prefix}/{name}'\n",
    "\n",
    "\n",
    "def bifpn_init(feature_maps: List[Any], num_channels: int, name: str) -> List[Any]:\n",
    "    pname = prefixer(name)\n",
    "    res = []\n",
    "    for i, features_in in enumerate(feature_maps):\n",
    "        features_out = tf.keras.layers.SeparableConv2D(\n",
    "            num_channels, kernel_size=3, strides=1, padding='same', name=pname(f'SeparableConv2D{i}'))(features_in)\n",
    "        res.append(features_out)\n",
    "    return res\n",
    "\n",
    "\n",
    "def SeparableConvBlock(num_channels: int, kernel_size: int, strides: int, gn_enabled: bool, name: str):\n",
    "    pname = prefixer(name)\n",
    "    f1 = tf.keras.layers.SeparableConv2D(num_channels, kernel_size=kernel_size, strides=strides, padding='same',\n",
    "        use_bias=True, name=pname('SeparableConv2D'))\n",
    "    if not gn_enabled:\n",
    "        return f1\n",
    "    \n",
    "    f2 = tfa.layers.GroupNormalization(groups=num_channels // 16)\n",
    "    return compose(f1, f2)\n",
    "\n",
    "\n",
    "class BifpnWeightedAdd(tf.keras.layers.Layer):\n",
    "    def __init__(self, epsilon=1e-4, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "        self.w = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        num_in = len(input_shape)\n",
    "        self.w = self.add_weight(name='w',\n",
    "                                 shape=(num_in,),\n",
    "                                 initializer=tf.keras.initializers.constant(1 / num_in),\n",
    "                                 trainable=True,\n",
    "                                 dtype=tf.float32)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        w = tf.keras.activations.relu(self.w)\n",
    "        x = tf.reduce_sum([w[i] * inputs[i] for i in range(len(inputs))], axis=0)\n",
    "        x = x / (tf.reduce_sum(w) + self.epsilon)\n",
    "        return x\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # Input is a list of similar shapes: [TensorShape[m, n], TensorShape[m, n], ...]\n",
    "        return input_shape[0]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            **super().get_config(),\n",
    "            'epsilon': self.epsilon,\n",
    "        }\n",
    "        return config\n",
    "\n",
    "\n",
    "def bifpn_merge(feature_maps_cur_level: List[Any], feature_map_other_level, upsample_other: bool, num_channels: int,\n",
    "        gn_enabled: bool, name: str):\n",
    "    pname = prefixer(name)\n",
    "    if upsample_other:\n",
    "        feature_map_resampled = tf.keras.layers.UpSampling2D(name=pname('UpSampling2D'))(feature_map_other_level)\n",
    "    else:\n",
    "        feature_map_resampled = tf.keras.layers.MaxPooling2D(\n",
    "            pool_size=3, strides=2, padding='same', name=pname('MaxPooling2D'))(feature_map_other_level)\n",
    "    \n",
    "    feature_map = BifpnWeightedAdd(name=pname('BifpnWeightedAdd'))(feature_maps_cur_level + [feature_map_resampled])\n",
    "    feature_map = tf.keras.activations.swish(feature_map)\n",
    "    feature_map = SeparableConvBlock(\n",
    "        num_channels=num_channels, kernel_size=3, strides=1, gn_enabled=gn_enabled, name=pname('SeparableConvBlock'))(feature_map)\n",
    "    return feature_map\n",
    "\n",
    "\n",
    "def bifpn_top_down(feature_maps: List[Any], num_channels: int, gn_enabled: bool, name: str) -> List[Any]:\n",
    "    pname = prefixer(name)\n",
    "    features_out = [feature_maps[0]]\n",
    "    for i in range(1, len(feature_maps)):\n",
    "        features_merged = bifpn_merge(\n",
    "            feature_maps_cur_level=[feature_maps[i]],\n",
    "            feature_map_other_level=features_out[-1],\n",
    "            upsample_other=True,\n",
    "            num_channels=num_channels,\n",
    "            gn_enabled=gn_enabled,\n",
    "            name=pname(f'merge{i}'))\n",
    "        features_out.append(features_merged)\n",
    "    return features_out\n",
    "\n",
    "\n",
    "def bifpn_bottom_up(feature_maps: List[List[Any]], num_channels: int, gn_enabled: bool, name: str) -> List[Any]:\n",
    "    pname = prefixer(name)\n",
    "    features_out = [feature_maps[0][0]]\n",
    "    for i in range(1, len(feature_maps)):\n",
    "        features_merged = bifpn_merge(\n",
    "            feature_maps_cur_level=feature_maps[i],\n",
    "            feature_map_other_level=features_out[-1],\n",
    "            upsample_other=False,\n",
    "            num_channels=num_channels,\n",
    "            gn_enabled=gn_enabled,\n",
    "            name=pname(f'merge{i}'),\n",
    "        )\n",
    "        features_out.append(features_merged)\n",
    "    return features_out\n",
    "    \n",
    "\n",
    "\n",
    "def bifpn_layer(feature_maps: List[Any], num_channels: int, gn_enabled: bool = True, name: str = 'BifpnLayer') -> List[Any]:\n",
    "    pname = prefixer(name)\n",
    "    feature_maps = list(reversed(feature_maps))\n",
    "    features_top_down = bifpn_top_down(feature_maps, num_channels, gn_enabled=gn_enabled, name=pname('BifpnTopDown'))\n",
    "    features_mid = []\n",
    "    n_maps = len(feature_maps)\n",
    "    for i in range(n_maps):\n",
    "        if 0 < i < n_maps - 1:\n",
    "            features_mid.append([feature_maps[i], features_top_down[i]])\n",
    "        else:\n",
    "            features_mid.append([features_top_down[i]])\n",
    "    \n",
    "    features_mid = list(reversed(features_mid))\n",
    "    features_bottom_up = bifpn_bottom_up(features_mid, num_channels, gn_enabled=gn_enabled, name=pname('BifpnBottomUp'))\n",
    "    \n",
    "    return features_bottom_up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method BifpnWeightedAdd.call of <__main__.BifpnWeightedAdd object at 0x7efe6c4fb4f0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method BifpnWeightedAdd.call of <__main__.BifpnWeightedAdd object at 0x7efe6c4fb4f0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "fpn_init_feature_maps = bifpn_init(bb_feature_maps, params.bifpn_width, name='BifpnInit')\n",
    "fpn_feature_maps = bifpn_layer(fpn_init_feature_maps, params.bifpn_width, name='Bifpn1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<KerasTensor: shape=(None, 256, 256, 64) dtype=float32 (created by layer 'group_normalization_11')>, <KerasTensor: shape=(None, 128, 128, 64) dtype=float32 (created by layer 'group_normalization_12')>, <KerasTensor: shape=(None, 64, 64, 64) dtype=float32 (created by layer 'group_normalization_13')>, <KerasTensor: shape=(None, 32, 32, 64) dtype=float32 (created by layer 'group_normalization_14')>, <KerasTensor: shape=(None, 16, 16, 64) dtype=float32 (created by layer 'group_normalization_15')>]\n"
     ]
    }
   ],
   "source": [
    "print(fpn_feature_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_upscale(fpn_feature_maps: List[Any], num_channels: int, name: str):\n",
    "    pname = prefixer(name)\n",
    "    feature_maps_in = []\n",
    "    for i, feature_map in enumerate(reversed(fpn_feature_maps)):\n",
    "        feature_map_in = tf.keras.layers.SeparableConv2D(\n",
    "            num_channels, kernel_size=3, strides=1, padding='same', name=pname(f'SeparableConv2D{i}'))(feature_map)\n",
    "        feature_maps_in.append(feature_map_in)\n",
    "    \n",
    "    feature_maps = bifpn_top_down(feature_maps_in, num_channels=num_channels, gn_enabled=False, name=pname('BifpnTopDown'))\n",
    "    feature_map_out = feature_maps[-1]\n",
    "    feature_map_out = tf.keras.layers.Conv2DTranspose(num_channels, kernel_size=3, strides=2, padding='same')(feature_map_out)\n",
    "    return feature_map_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ouput channels: 33\n"
     ]
    }
   ],
   "source": [
    "n_classes = 28\n",
    "n_channels_normals = 3\n",
    "n_channels_cmap = 1\n",
    "n_channels_contours = 1\n",
    "n_channels_out = n_classes + n_channels_normals + n_channels_cmap + n_channels_contours\n",
    "print(f'Ouput channels: {n_channels_out}')\n",
    "features_out = final_upscale(fpn_feature_maps, n_channels_out, name='FinalUpscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv (Conv2D)              (None, 256, 256, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stem_bn (BatchNormalization)    (None, 256, 256, 32) 128         stem_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_activation (Activation)    (None, 256, 256, 32) 0           stem_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1b_dwconv (DepthwiseConv2D (None, 256, 256, 32) 288         stem_activation[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1b_bn (BatchNormalization) (None, 256, 256, 32) 128         block1b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1b_activation (Activation) (None, 256, 256, 32) 0           block1b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_squeeze (GlobalAvera (None, 32)           0           block1b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_excite (Multiply)    (None, 256, 256, 32) 0           block1b_activation[0][0]         \n",
      "                                                                 block1b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_conv (Conv2D)   (None, 256, 256, 16) 512         block1b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_bn (BatchNormal (None, 256, 256, 16) 64          block1b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_conv (Conv2D)    (None, 256, 256, 96) 1536        block1b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_bn (BatchNormali (None, 256, 256, 96) 384         block2b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_activation (Acti (None, 256, 256, 96) 0           block2b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_dwconv (DepthwiseConv2D (None, 128, 128, 96) 864         block2b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2b_bn (BatchNormalization) (None, 128, 128, 96) 384         block2b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2b_activation (Activation) (None, 128, 128, 96) 0           block2b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_squeeze (GlobalAvera (None, 96)           0           block2b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reshape (Reshape)    (None, 1, 1, 96)     0           block2b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reduce (Conv2D)      (None, 1, 1, 4)      388         block2b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_expand (Conv2D)      (None, 1, 1, 96)     480         block2b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_excite (Multiply)    (None, 128, 128, 96) 0           block2b_activation[0][0]         \n",
      "                                                                 block2b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_conv (Conv2D)   (None, 128, 128, 24) 2304        block2b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_bn (BatchNormal (None, 128, 128, 24) 96          block2b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_conv (Conv2D)    (None, 128, 128, 144 3456        block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_bn (BatchNormali (None, 128, 128, 144 576         block2c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_activation (Acti (None, 128, 128, 144 0           block2c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_dwconv (DepthwiseConv2D (None, 128, 128, 144 1296        block2c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2c_bn (BatchNormalization) (None, 128, 128, 144 576         block2c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2c_activation (Activation) (None, 128, 128, 144 0           block2c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_squeeze (GlobalAvera (None, 144)          0           block2c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_excite (Multiply)    (None, 128, 128, 144 0           block2c_activation[0][0]         \n",
      "                                                                 block2c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_conv (Conv2D)   (None, 128, 128, 24) 3456        block2c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_bn (BatchNormal (None, 128, 128, 24) 96          block2c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2c_drop (Dropout)          (None, 128, 128, 24) 0           block2c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_add (Add)               (None, 128, 128, 24) 0           block2c_drop[0][0]               \n",
      "                                                                 block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_conv (Conv2D)    (None, 128, 128, 144 3456        block2c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_bn (BatchNormali (None, 128, 128, 144 576         block3b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_activation (Acti (None, 128, 128, 144 0           block3b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_dwconv (DepthwiseConv2D (None, 64, 64, 144)  3600        block3b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3b_bn (BatchNormalization) (None, 64, 64, 144)  576         block3b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3b_activation (Activation) (None, 64, 64, 144)  0           block3b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_squeeze (GlobalAvera (None, 144)          0           block3b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reshape (Reshape)    (None, 1, 1, 144)    0           block3b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block3b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block3b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_excite (Multiply)    (None, 64, 64, 144)  0           block3b_activation[0][0]         \n",
      "                                                                 block3b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_conv (Conv2D)   (None, 64, 64, 40)   5760        block3b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_bn (BatchNormal (None, 64, 64, 40)   160         block3b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_conv (Conv2D)    (None, 64, 64, 240)  9600        block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_bn (BatchNormali (None, 64, 64, 240)  960         block3c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_activation (Acti (None, 64, 64, 240)  0           block3c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_dwconv (DepthwiseConv2D (None, 64, 64, 240)  6000        block3c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3c_bn (BatchNormalization) (None, 64, 64, 240)  960         block3c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3c_activation (Activation) (None, 64, 64, 240)  0           block3c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_squeeze (GlobalAvera (None, 240)          0           block3c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reshape (Reshape)    (None, 1, 1, 240)    0           block3c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block3c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block3c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_excite (Multiply)    (None, 64, 64, 240)  0           block3c_activation[0][0]         \n",
      "                                                                 block3c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_conv (Conv2D)   (None, 64, 64, 40)   9600        block3c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_bn (BatchNormal (None, 64, 64, 40)   160         block3c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3c_drop (Dropout)          (None, 64, 64, 40)   0           block3c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_add (Add)               (None, 64, 64, 40)   0           block3c_drop[0][0]               \n",
      "                                                                 block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_conv (Conv2D)    (None, 64, 64, 240)  9600        block3c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_bn (BatchNormali (None, 64, 64, 240)  960         block4b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_activation (Acti (None, 64, 64, 240)  0           block4b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_dwconv (DepthwiseConv2D (None, 32, 32, 240)  2160        block4b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4b_bn (BatchNormalization) (None, 32, 32, 240)  960         block4b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4b_activation (Activation) (None, 32, 32, 240)  0           block4b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_squeeze (GlobalAvera (None, 240)          0           block4b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reshape (Reshape)    (None, 1, 1, 240)    0           block4b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block4b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block4b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_excite (Multiply)    (None, 32, 32, 240)  0           block4b_activation[0][0]         \n",
      "                                                                 block4b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_conv (Conv2D)   (None, 32, 32, 80)   19200       block4b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_bn (BatchNormal (None, 32, 32, 80)   320         block4b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_conv (Conv2D)    (None, 32, 32, 480)  38400       block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_bn (BatchNormali (None, 32, 32, 480)  1920        block4c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_activation (Acti (None, 32, 32, 480)  0           block4c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_dwconv (DepthwiseConv2D (None, 32, 32, 480)  4320        block4c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4c_bn (BatchNormalization) (None, 32, 32, 480)  1920        block4c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4c_activation (Activation) (None, 32, 32, 480)  0           block4c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_squeeze (GlobalAvera (None, 480)          0           block4c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_excite (Multiply)    (None, 32, 32, 480)  0           block4c_activation[0][0]         \n",
      "                                                                 block4c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_conv (Conv2D)   (None, 32, 32, 80)   38400       block4c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_bn (BatchNormal (None, 32, 32, 80)   320         block4c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_drop (Dropout)          (None, 32, 32, 80)   0           block4c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_add (Add)               (None, 32, 32, 80)   0           block4c_drop[0][0]               \n",
      "                                                                 block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_conv (Conv2D)    (None, 32, 32, 480)  38400       block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_bn (BatchNormali (None, 32, 32, 480)  1920        block4d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_activation (Acti (None, 32, 32, 480)  0           block4d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_dwconv (DepthwiseConv2D (None, 32, 32, 480)  4320        block4d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4d_bn (BatchNormalization) (None, 32, 32, 480)  1920        block4d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4d_activation (Activation) (None, 32, 32, 480)  0           block4d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_squeeze (GlobalAvera (None, 480)          0           block4d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_excite (Multiply)    (None, 32, 32, 480)  0           block4d_activation[0][0]         \n",
      "                                                                 block4d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_conv (Conv2D)   (None, 32, 32, 80)   38400       block4d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_bn (BatchNormal (None, 32, 32, 80)   320         block4d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4d_drop (Dropout)          (None, 32, 32, 80)   0           block4d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_add (Add)               (None, 32, 32, 80)   0           block4d_drop[0][0]               \n",
      "                                                                 block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_conv (Conv2D)    (None, 32, 32, 480)  38400       block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_bn (BatchNormali (None, 32, 32, 480)  1920        block5b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_activation (Acti (None, 32, 32, 480)  0           block5b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_dwconv (DepthwiseConv2D (None, 32, 32, 480)  12000       block5b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5b_bn (BatchNormalization) (None, 32, 32, 480)  1920        block5b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5b_activation (Activation) (None, 32, 32, 480)  0           block5b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_squeeze (GlobalAvera (None, 480)          0           block5b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reshape (Reshape)    (None, 1, 1, 480)    0           block5b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block5b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block5b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_excite (Multiply)    (None, 32, 32, 480)  0           block5b_activation[0][0]         \n",
      "                                                                 block5b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_conv (Conv2D)   (None, 32, 32, 112)  53760       block5b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_bn (BatchNormal (None, 32, 32, 112)  448         block5b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_conv (Conv2D)    (None, 32, 32, 672)  75264       block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_bn (BatchNormali (None, 32, 32, 672)  2688        block5c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_activation (Acti (None, 32, 32, 672)  0           block5c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_dwconv (DepthwiseConv2D (None, 32, 32, 672)  16800       block5c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5c_bn (BatchNormalization) (None, 32, 32, 672)  2688        block5c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5c_activation (Activation) (None, 32, 32, 672)  0           block5c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_squeeze (GlobalAvera (None, 672)          0           block5c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_excite (Multiply)    (None, 32, 32, 672)  0           block5c_activation[0][0]         \n",
      "                                                                 block5c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_conv (Conv2D)   (None, 32, 32, 112)  75264       block5c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_bn (BatchNormal (None, 32, 32, 112)  448         block5c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_drop (Dropout)          (None, 32, 32, 112)  0           block5c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_add (Add)               (None, 32, 32, 112)  0           block5c_drop[0][0]               \n",
      "                                                                 block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_conv (Conv2D)    (None, 32, 32, 672)  75264       block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_bn (BatchNormali (None, 32, 32, 672)  2688        block5d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_activation (Acti (None, 32, 32, 672)  0           block5d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_dwconv (DepthwiseConv2D (None, 32, 32, 672)  16800       block5d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5d_bn (BatchNormalization) (None, 32, 32, 672)  2688        block5d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5d_activation (Activation) (None, 32, 32, 672)  0           block5d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_squeeze (GlobalAvera (None, 672)          0           block5d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_excite (Multiply)    (None, 32, 32, 672)  0           block5d_activation[0][0]         \n",
      "                                                                 block5d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_conv (Conv2D)   (None, 32, 32, 112)  75264       block5d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_bn (BatchNormal (None, 32, 32, 112)  448         block5d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5d_drop (Dropout)          (None, 32, 32, 112)  0           block5d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_add (Add)               (None, 32, 32, 112)  0           block5d_drop[0][0]               \n",
      "                                                                 block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_conv (Conv2D)    (None, 32, 32, 672)  75264       block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_bn (BatchNormali (None, 32, 32, 672)  2688        block6b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_activation (Acti (None, 32, 32, 672)  0           block6b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_dwconv (DepthwiseConv2D (None, 16, 16, 672)  16800       block6b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6b_bn (BatchNormalization) (None, 16, 16, 672)  2688        block6b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6b_activation (Activation) (None, 16, 16, 672)  0           block6b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_squeeze (GlobalAvera (None, 672)          0           block6b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reshape (Reshape)    (None, 1, 1, 672)    0           block6b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block6b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block6b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_excite (Multiply)    (None, 16, 16, 672)  0           block6b_activation[0][0]         \n",
      "                                                                 block6b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_conv (Conv2D)   (None, 16, 16, 192)  129024      block6b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_bn (BatchNormal (None, 16, 16, 192)  768         block6b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_conv (Conv2D)    (None, 16, 16, 1152) 221184      block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_bn (BatchNormali (None, 16, 16, 1152) 4608        block6c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_activation (Acti (None, 16, 16, 1152) 0           block6c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_dwconv (DepthwiseConv2D (None, 16, 16, 1152) 28800       block6c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6c_bn (BatchNormalization) (None, 16, 16, 1152) 4608        block6c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6c_activation (Activation) (None, 16, 16, 1152) 0           block6c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_squeeze (GlobalAvera (None, 1152)         0           block6c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_excite (Multiply)    (None, 16, 16, 1152) 0           block6c_activation[0][0]         \n",
      "                                                                 block6c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_conv (Conv2D)   (None, 16, 16, 192)  221184      block6c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_bn (BatchNormal (None, 16, 16, 192)  768         block6c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_drop (Dropout)          (None, 16, 16, 192)  0           block6c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_add (Add)               (None, 16, 16, 192)  0           block6c_drop[0][0]               \n",
      "                                                                 block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_conv (Conv2D)    (None, 16, 16, 1152) 221184      block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_bn (BatchNormali (None, 16, 16, 1152) 4608        block6d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_activation (Acti (None, 16, 16, 1152) 0           block6d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_dwconv (DepthwiseConv2D (None, 16, 16, 1152) 28800       block6d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6d_bn (BatchNormalization) (None, 16, 16, 1152) 4608        block6d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6d_activation (Activation) (None, 16, 16, 1152) 0           block6d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_squeeze (GlobalAvera (None, 1152)         0           block6d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_excite (Multiply)    (None, 16, 16, 1152) 0           block6d_activation[0][0]         \n",
      "                                                                 block6d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_conv (Conv2D)   (None, 16, 16, 192)  221184      block6d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_bn (BatchNormal (None, 16, 16, 192)  768         block6d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6d_drop (Dropout)          (None, 16, 16, 192)  0           block6d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_add (Add)               (None, 16, 16, 192)  0           block6d_drop[0][0]               \n",
      "                                                                 block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_conv (Conv2D)    (None, 16, 16, 1152) 221184      block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_bn (BatchNormali (None, 16, 16, 1152) 4608        block6e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_activation (Acti (None, 16, 16, 1152) 0           block6e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_dwconv (DepthwiseConv2D (None, 16, 16, 1152) 28800       block6e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6e_bn (BatchNormalization) (None, 16, 16, 1152) 4608        block6e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6e_activation (Activation) (None, 16, 16, 1152) 0           block6e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_squeeze (GlobalAvera (None, 1152)         0           block6e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_excite (Multiply)    (None, 16, 16, 1152) 0           block6e_activation[0][0]         \n",
      "                                                                 block6e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_conv (Conv2D)   (None, 16, 16, 192)  221184      block6e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_bn (BatchNormal (None, 16, 16, 192)  768         block6e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6e_drop (Dropout)          (None, 16, 16, 192)  0           block6e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_add (Add)               (None, 16, 16, 192)  0           block6e_drop[0][0]               \n",
      "                                                                 block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_conv (Conv2D)    (None, 16, 16, 1152) 221184      block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_bn (BatchNormali (None, 16, 16, 1152) 4608        block7b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_activation (Acti (None, 16, 16, 1152) 0           block7b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_dwconv (DepthwiseConv2D (None, 16, 16, 1152) 10368       block7b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7b_bn (BatchNormalization) (None, 16, 16, 1152) 4608        block7b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7b_activation (Activation) (None, 16, 16, 1152) 0           block7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_squeeze (GlobalAvera (None, 1152)         0           block7b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block7b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block7b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block7b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_excite (Multiply)    (None, 16, 16, 1152) 0           block7b_activation[0][0]         \n",
      "                                                                 block7b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_conv (Conv2D)   (None, 16, 16, 320)  368640      block7b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_bn (BatchNormal (None, 16, 16, 320)  1280        block7b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "BifpnInit/SeparableConv2D4 (Sep (None, 16, 16, 64)   23424       block7b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BifpnInit/SeparableConv2D3 (Sep (None, 32, 32, 64)   8240        block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Bifpn1/BifpnTopDown/merge1/UpSa (None, 32, 32, 64)   0           BifpnInit/SeparableConv2D4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Bifpn1/BifpnTopDown/merge1/Bifp (None, 32, 32, 64)   2           BifpnInit/SeparableConv2D3[0][0] \n",
      "                                                                 Bifpn1/BifpnTopDown/merge1/UpSamp\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.silu_8 (TFOpLambda)       (None, 32, 32, 64)   0           Bifpn1/BifpnTopDown/merge1/BifpnW\n",
      "__________________________________________________________________________________________________\n",
      "Bifpn1/BifpnTopDown/merge1/Sepa (None, 32, 32, 64)   4736        tf.nn.silu_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_8 (GroupNor (None, 32, 32, 64)   128         Bifpn1/BifpnTopDown/merge1/Separa\n",
      "__________________________________________________________________________________________________\n",
      "BifpnInit/SeparableConv2D2 (Sep (None, 64, 64, 64)   2984        block3c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Bifpn1/BifpnTopDown/merge2/UpSa (None, 64, 64, 64)   0           group_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Bifpn1/BifpnTopDown/merge2/Bifp (None, 64, 64, 64)   2           BifpnInit/SeparableConv2D2[0][0] \n",
      "                                                                 Bifpn1/BifpnTopDown/merge2/UpSamp\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.silu_9 (TFOpLambda)       (None, 64, 64, 64)   0           Bifpn1/BifpnTopDown/merge2/BifpnW\n",
      "__________________________________________________________________________________________________\n",
      "Bifpn1/BifpnTopDown/merge2/Sepa (None, 64, 64, 64)   4736        tf.nn.silu_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_9 (GroupNor (None, 64, 64, 64)   128         Bifpn1/BifpnTopDown/merge2/Separa\n",
      "__________________________________________________________________________________________________\n",
      "BifpnInit/SeparableConv2D1 (Sep (None, 128, 128, 64) 1816        block2c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Bifpn1/BifpnTopDown/merge3/UpSa (None, 128, 128, 64) 0           group_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Bifpn1/BifpnTopDown/merge3/Bifp (None, 128, 128, 64) 2           BifpnInit/SeparableConv2D1[0][0] \n",
      "                                                                 Bifpn1/BifpnTopDown/merge3/UpSamp\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.silu_10 (TFOpLambda)      (None, 128, 128, 64) 0           Bifpn1/BifpnTopDown/merge3/BifpnW\n",
      "__________________________________________________________________________________________________\n",
      "Bifpn1/BifpnTopDown/merge3/Sepa (None, 128, 128, 64) 4736        tf.nn.silu_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_10 (GroupNo (None, 128, 128, 64) 128         Bifpn1/BifpnTopDown/merge3/Separa\n",
      "__________________________________________________________________________________________________\n",
      "BifpnInit/SeparableConv2D0 (Sep (None, 256, 256, 64) 1232        block1b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Bifpn1/BifpnTopDown/merge4/UpSa (None, 256, 256, 64) 0           group_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Bifpn1/BifpnTopDown/merge4/Bifp (None, 256, 256, 64) 2           BifpnInit/SeparableConv2D0[0][0] \n",
      "                                                                 Bifpn1/BifpnTopDown/merge4/UpSamp\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.silu_11 (TFOpLambda)      (None, 256, 256, 64) 0           Bifpn1/BifpnTopDown/merge4/BifpnW\n",
      "__________________________________________________________________________________________________\n",
      "Bifpn1/BifpnTopDown/merge4/Sepa (None, 256, 256, 64) 4736        tf.nn.silu_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_11 (GroupNo (None, 256, 256, 64) 128         Bifpn1/BifpnTopDown/merge4/Separa\n",
      "__________________________________________________________________________________________________\n",
      "Bifpn1/BifpnBottomUp/merge1/Max (None, 128, 128, 64) 0           group_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Bifpn1/BifpnBottomUp/merge1/Bif (None, 128, 128, 64) 3           BifpnInit/SeparableConv2D1[0][0] \n",
      "                                                                 group_normalization_10[0][0]     \n",
      "                                                                 Bifpn1/BifpnBottomUp/merge1/MaxPo\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.silu_12 (TFOpLambda)      (None, 128, 128, 64) 0           Bifpn1/BifpnBottomUp/merge1/Bifpn\n",
      "__________________________________________________________________________________________________\n",
      "Bifpn1/BifpnBottomUp/merge1/Sep (None, 128, 128, 64) 4736        tf.nn.silu_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_12 (GroupNo (None, 128, 128, 64) 128         Bifpn1/BifpnBottomUp/merge1/Separ\n",
      "__________________________________________________________________________________________________\n",
      "Bifpn1/BifpnBottomUp/merge2/Max (None, 64, 64, 64)   0           group_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Bifpn1/BifpnBottomUp/merge2/Bif (None, 64, 64, 64)   3           BifpnInit/SeparableConv2D2[0][0] \n",
      "                                                                 group_normalization_9[0][0]      \n",
      "                                                                 Bifpn1/BifpnBottomUp/merge2/MaxPo\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.silu_13 (TFOpLambda)      (None, 64, 64, 64)   0           Bifpn1/BifpnBottomUp/merge2/Bifpn\n",
      "__________________________________________________________________________________________________\n",
      "Bifpn1/BifpnBottomUp/merge2/Sep (None, 64, 64, 64)   4736        tf.nn.silu_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_13 (GroupNo (None, 64, 64, 64)   128         Bifpn1/BifpnBottomUp/merge2/Separ\n",
      "__________________________________________________________________________________________________\n",
      "Bifpn1/BifpnBottomUp/merge3/Max (None, 32, 32, 64)   0           group_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Bifpn1/BifpnBottomUp/merge3/Bif (None, 32, 32, 64)   3           BifpnInit/SeparableConv2D3[0][0] \n",
      "                                                                 group_normalization_8[0][0]      \n",
      "                                                                 Bifpn1/BifpnBottomUp/merge3/MaxPo\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.silu_14 (TFOpLambda)      (None, 32, 32, 64)   0           Bifpn1/BifpnBottomUp/merge3/Bifpn\n",
      "__________________________________________________________________________________________________\n",
      "Bifpn1/BifpnBottomUp/merge3/Sep (None, 32, 32, 64)   4736        tf.nn.silu_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_14 (GroupNo (None, 32, 32, 64)   128         Bifpn1/BifpnBottomUp/merge3/Separ\n",
      "__________________________________________________________________________________________________\n",
      "Bifpn1/BifpnBottomUp/merge4/Max (None, 16, 16, 64)   0           group_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Bifpn1/BifpnBottomUp/merge4/Bif (None, 16, 16, 64)   2           BifpnInit/SeparableConv2D4[0][0] \n",
      "                                                                 Bifpn1/BifpnBottomUp/merge4/MaxPo\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.silu_15 (TFOpLambda)      (None, 16, 16, 64)   0           Bifpn1/BifpnBottomUp/merge4/Bifpn\n",
      "__________________________________________________________________________________________________\n",
      "Bifpn1/BifpnBottomUp/merge4/Sep (None, 16, 16, 64)   4736        tf.nn.silu_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_15 (GroupNo (None, 16, 16, 64)   128         Bifpn1/BifpnBottomUp/merge4/Separ\n",
      "__________________________________________________________________________________________________\n",
      "FinalUpscale/SeparableConv2D0 ( (None, 16, 16, 33)   2721        group_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "FinalUpscale/SeparableConv2D1 ( (None, 32, 32, 33)   2721        group_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "FinalUpscale/BifpnTopDown/merge (None, 32, 32, 33)   0           FinalUpscale/SeparableConv2D0[0][\n",
      "__________________________________________________________________________________________________\n",
      "FinalUpscale/BifpnTopDown/merge (None, 32, 32, 33)   2           FinalUpscale/SeparableConv2D1[0][\n",
      "                                                                 FinalUpscale/BifpnTopDown/merge1/\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.silu_16 (TFOpLambda)      (None, 32, 32, 33)   0           FinalUpscale/BifpnTopDown/merge1/\n",
      "__________________________________________________________________________________________________\n",
      "FinalUpscale/BifpnTopDown/merge (None, 32, 32, 33)   1419        tf.nn.silu_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "FinalUpscale/SeparableConv2D2 ( (None, 64, 64, 33)   2721        group_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "FinalUpscale/BifpnTopDown/merge (None, 64, 64, 33)   0           FinalUpscale/BifpnTopDown/merge1/\n",
      "__________________________________________________________________________________________________\n",
      "FinalUpscale/BifpnTopDown/merge (None, 64, 64, 33)   2           FinalUpscale/SeparableConv2D2[0][\n",
      "                                                                 FinalUpscale/BifpnTopDown/merge2/\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.silu_17 (TFOpLambda)      (None, 64, 64, 33)   0           FinalUpscale/BifpnTopDown/merge2/\n",
      "__________________________________________________________________________________________________\n",
      "FinalUpscale/BifpnTopDown/merge (None, 64, 64, 33)   1419        tf.nn.silu_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "FinalUpscale/SeparableConv2D3 ( (None, 128, 128, 33) 2721        group_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "FinalUpscale/BifpnTopDown/merge (None, 128, 128, 33) 0           FinalUpscale/BifpnTopDown/merge2/\n",
      "__________________________________________________________________________________________________\n",
      "FinalUpscale/BifpnTopDown/merge (None, 128, 128, 33) 2           FinalUpscale/SeparableConv2D3[0][\n",
      "                                                                 FinalUpscale/BifpnTopDown/merge3/\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.silu_18 (TFOpLambda)      (None, 128, 128, 33) 0           FinalUpscale/BifpnTopDown/merge3/\n",
      "__________________________________________________________________________________________________\n",
      "FinalUpscale/BifpnTopDown/merge (None, 128, 128, 33) 1419        tf.nn.silu_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "FinalUpscale/SeparableConv2D4 ( (None, 256, 256, 33) 2721        group_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "FinalUpscale/BifpnTopDown/merge (None, 256, 256, 33) 0           FinalUpscale/BifpnTopDown/merge3/\n",
      "__________________________________________________________________________________________________\n",
      "FinalUpscale/BifpnTopDown/merge (None, 256, 256, 33) 2           FinalUpscale/SeparableConv2D4[0][\n",
      "                                                                 FinalUpscale/BifpnTopDown/merge4/\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.silu_19 (TFOpLambda)      (None, 256, 256, 33) 0           FinalUpscale/BifpnTopDown/merge4/\n",
      "__________________________________________________________________________________________________\n",
      "FinalUpscale/BifpnTopDown/merge (None, 256, 256, 33) 1419        tf.nn.silu_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 512, 512, 33) 9834        FinalUpscale/BifpnTopDown/merge4/\n",
      "==================================================================================================\n",
      "Total params: 3,740,594\n",
      "Trainable params: 3,661,682\n",
      "Non-trainable params: 78,912\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Model(inputs=[image_input], outputs=features_out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'batch_normalization_9/moving_mean:0' shape=(3,) dtype=float32, numpy=array([1., 1., 1.], dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_10/moving_mean:0' shape=(2,) dtype=float32, numpy=array([1., 1.], dtype=float32)>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BN1.moving_mean, BN2.moving_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/misha/prog/sixd_sense/sds',\n",
       " '/home/misha/.vscode-insiders/extensions/ms-toolsai.jupyter-2022.1.1001614873/pythonFiles',\n",
       " '/home/misha/.vscode-insiders/extensions/ms-toolsai.jupyter-2022.1.1001614873/pythonFiles/lib/python',\n",
       " '/home/misha/anaconda3/envs/bop/lib/python39.zip',\n",
       " '/home/misha/anaconda3/envs/bop/lib/python3.9',\n",
       " '/home/misha/anaconda3/envs/bop/lib/python3.9/lib-dynload',\n",
       " '',\n",
       " '/home/misha/anaconda3/envs/bop/lib/python3.9/site-packages',\n",
       " '/home/misha/prog/lib/BlenderProc',\n",
       " '/home/misha/anaconda3/envs/bop/lib/python3.9/site-packages/IPython/extensions',\n",
       " '/home/misha/.ipython',\n",
       " '/home/misha/.local/lib/python3.9/site-packages']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
       "array([[16., 12.],\n",
       "       [19.,  9.],\n",
       "       [ 4., 11.],\n",
       "       [ 5.,  2.],\n",
       "       [17., 11.]], dtype=float32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform((5, 2), 1, 20, tf.int32)\n",
    "x = tf.cast(x, tf.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dropout at 0x7fc9ec08b310>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp = tf.keras.layers.Dropout(0.2, (None, 1))\n",
    "dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
       "array([[20.  , 15.  ],\n",
       "       [23.75, 11.25],\n",
       "       [ 0.  ,  0.  ],\n",
       "       [ 6.25,  2.5 ],\n",
       "       [ 0.  ,  0.  ]], dtype=float32)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp(x, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.engine.keras_tensor.KerasTensor"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = tf.keras.Input((None, 2, 3))\n",
    "type(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(object,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.__class__.__bases__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dp(x, training=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BlockArgs(kernel_size=3, num_repeat=1, input_filters=32, output_filters=16, expand_ratio=1, id_skip=True, strides=(1, 1), se_ratio=0.25)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ba = DEFAULT_BLOCKS_ARGS[0]\n",
    "ba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__main__.BlockArgs() got multiple values for keyword argument 'num_repeat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_219913/1753678677.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mBlockArgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_repeat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __main__.BlockArgs() got multiple values for keyword argument 'num_repeat'"
     ]
    }
   ],
   "source": [
    "BlockArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel_size': 3,\n",
       " 'num_repeat': 2,\n",
       " 'input_filters': 32,\n",
       " 'output_filters': 16,\n",
       " 'expand_ratio': 1,\n",
       " 'id_skip': True,\n",
       " 'strides': (1, 1),\n",
       " 'se_ratio': 0.25}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{**vars(ba), 'num_repeat': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(BlockArgs(kernel_size=3, num_repeat=1, input_filters=32, output_filters=16, expand_ratio=1, id_skip=True, strides=(1, 1), se_ratio=0.25),\n",
       " BlockArgs(kernel_size=3, num_repeat=22, input_filters=32, output_filters=16, expand_ratio=1, id_skip=True, strides=(1, 1), se_ratio=0.25))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import copy\n",
    "ba1 = copy(ba)\n",
    "ba1.num_repeat = 22\n",
    "ba, ba1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 1, 2), dtype=string, numpy=\n",
       " array([[[b'a1', b'b1']],\n",
       " \n",
       "        [[b'c0', b'd0']]], dtype=object)>,\n",
       " <tf.Tensor: shape=(2, 1), dtype=string, numpy=\n",
       " array([[b'c0'],\n",
       "        [b'b1']], dtype=object)>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = tf.constant([[['a0', 'b0'], ['c0', 'd0']],\n",
    "              [['a1', 'b1'], ['c1', 'd1']]])\n",
    "indices = [[[1, 0]], [[0, 1]]]\n",
    "tf.gather_nd(params, indices), tf.gather_nd(params, indices, batch_dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba1 = dcls.replace(ba, num_repeat=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(BlockArgs(kernel_size=3, num_repeat=1, input_filters=32, output_filters=16, expand_ratio=1, id_skip=True, strides=(1, 1), se_ratio=0.25),\n",
       " BlockArgs(kernel_size=3, num_repeat=3, input_filters=32, output_filters=16, expand_ratio=1, id_skip=True, strides=(1, 1), se_ratio=0.25))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ba, ba1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BlockArgs(kernel_size=3, num_repeat=1, input_filters=32, output_filters=16, expand_ratio=1, id_skip=True, strides=(1, 1), se_ratio=0.25)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BlockArgs(kernel_size=3, num_repeat=2, input_filters=40, output_filters=24, expand_ratio=1, id_skip=True, strides=(1, 1), se_ratio=0.25)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_args = DEFAULT_BLOCKS_ARGS[0]\n",
    "print(block_args)\n",
    "width_coefficient, depth_coefficient, depth_divisor = 1.2, 1.4, 8\n",
    "dcls.replace(block_args,\n",
    "            input_filters=round_filters(block_args.input_filters, width_coefficient, depth_divisor),\n",
    "            output_filters=round_filters(block_args.output_filters, width_coefficient, depth_divisor),\n",
    "            num_repeat=round_repeats(block_args.num_repeat, depth_coefficient))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 23:51:06.058539: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-01-09 23:51:06.059416: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-01-09 23:51:06.086014: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2022-01-09 23:51:06.086047: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: train\n",
      "2022-01-09 23:51:06.086054: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: train\n",
      "2022-01-09 23:51:06.086138: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 470.86.0\n",
      "2022-01-09 23:51:06.086161: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 470.86.0\n",
      "2022-01-09 23:51:06.086166: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 470.86.0\n",
      "2022-01-09 23:51:06.086736: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-09 23:51:06.087074: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 3, 4), dtype=float32, numpy=\n",
       "array([[[[0.4745221 , 0.11489785, 0.12162721, 0.07320273],\n",
       "         [0.9412204 , 0.7219523 , 0.9624729 , 0.0850718 ],\n",
       "         [0.9367769 , 0.5110214 , 0.83429956, 0.5570532 ]],\n",
       "\n",
       "        [[0.4119432 , 0.575389  , 0.7608855 , 0.33425868],\n",
       "         [0.23874879, 0.34591877, 0.4665196 , 0.5286418 ],\n",
       "         [0.0789181 , 0.7882943 , 0.16099072, 0.41588652]],\n",
       "\n",
       "        [[0.04509509, 0.0629158 , 0.9308244 , 0.47065175],\n",
       "         [0.43653476, 0.9777608 , 0.81097436, 0.4424522 ],\n",
       "         [0.94104016, 0.05488026, 0.95357215, 0.7789507 ]]],\n",
       "\n",
       "\n",
       "       [[[0.02088416, 0.37490594, 0.49665165, 0.6692965 ],\n",
       "         [0.49432635, 0.93393123, 0.4224975 , 0.40523756],\n",
       "         [0.62095666, 0.03527641, 0.31722033, 0.07540357]],\n",
       "\n",
       "        [[0.99739444, 0.09169388, 0.97013843, 0.8367541 ],\n",
       "         [0.9673866 , 0.52303195, 0.23018289, 0.02071369],\n",
       "         [0.5157801 , 0.42481792, 0.6533141 , 0.03869045]],\n",
       "\n",
       "        [[0.77005005, 0.05051482, 0.5765488 , 0.41628337],\n",
       "         [0.94730806, 0.404611  , 0.6090975 , 0.737867  ],\n",
       "         [0.9584451 , 0.48939562, 0.11242139, 0.7163775 ]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.random.uniform((2, 3, 3, 4))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = tf.keras.activations.softmax(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(t2, np.ones(t2.get_shape()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.keras.initializers.random_uniform(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 3), dtype=float32, numpy=\n",
       "array([[[4.4560995e+00, 2.6941299e-03, 8.4572754e+00],\n",
       "        [8.5883799e+00, 6.0469198e+00, 2.9005849e+00]],\n",
       "\n",
       "       [[3.6264551e+00, 6.6117930e+00, 8.4459186e-01],\n",
       "        [5.9046197e+00, 6.6545572e+00, 1.9151568e+00]]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = init((2, 2, 3))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2), dtype=float32, numpy=\n",
       "array([[[4.4560995e+00, 2.6941299e-03],\n",
       "        [8.5883799e+00, 6.0469198e+00]],\n",
       "\n",
       "       [[3.6264551e+00, 6.6117930e+00],\n",
       "        [5.9046197e+00, 6.6545572e+00]]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[..., :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2b3ee2e22684e028c30651d552db890136561fe08566597ead86e882d739bf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('bop': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
