{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-20 12:14:51.513379: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sds.utils.common'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_gnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtfgnn\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_gnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgcn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgcn_conv\u001b[39;00m \u001b[39mimport\u001b[39;00m GCNHomGraphUpdate\n\u001b[0;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msds\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommon\u001b[39;00m \u001b[39mimport\u001b[39;00m IntOrTuple, int_to_tuple\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msds\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m calc_3d_graph_elevated\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sds.utils.common'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "cwd = Path(os.getcwd()).parent.as_posix()\n",
    "if cwd not in sys.path:\n",
    "    sys.path.append(cwd)\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from typing import Tuple, Union, Callable, Optional, Any\n",
    "import tensorflow_gnn as tfgnn\n",
    "from tensorflow_gnn.models.gcn.gcn_conv import GCNHomGraphUpdate\n",
    "\n",
    "from sds.utils.common import IntOrTuple, int_to_tuple\n",
    "from sds.utils.utils import calc_3d_graph_elevated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotHeadType(Enum):\n",
    "    Conv2d = 'conv2d'\n",
    "    Conv3d = 'conv3d'\n",
    "\n",
    "ROT_HEAD_TYPE_VALUES = [ht.value for ht in RotHeadType]\n",
    "Activation = Callable[[Any], Any]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_down(x: Any, strides: IntOrTuple, ch_in: int, ch_out: int = 0, kernel_size: IntOrTuple = 5,\n",
    "               act: Any = tf.nn.relu) -> Tuple[Any, int]:\n",
    "    strides = int_to_tuple(strides)\n",
    "    if not ch_out:\n",
    "        ch_out = ch_in * strides[0] * strides[1]\n",
    "    x = tf.keras.layers.Conv2D(ch_out, kernel_size, strides, 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    if act is not None:\n",
    "        x = act(x)\n",
    "    return x, ch_out\n",
    "\n",
    "\n",
    "def block_up(x: Any, strides: IntOrTuple, ch_in: int, ch_out: int = 0, kernel_size: IntOrTuple = 4,\n",
    "             act: Any = tf.nn.relu) -> Tuple[Any, int]:\n",
    "    strides = int_to_tuple(strides)\n",
    "    if not ch_out:\n",
    "        ch_out = ch_in // (strides[0] * strides[1])\n",
    "    x = tf.keras.layers.Conv2DTranspose(ch_out, kernel_size, strides, 'same')(x)\n",
    "    if act is not None:\n",
    "        x = act(x)\n",
    "    return x, ch_out\n",
    "\n",
    "\n",
    "def is_pow_2(n: int) -> bool:\n",
    "    while n > 1:\n",
    "        if n % 2: return False\n",
    "        n //= 2\n",
    "    return True\n",
    "\n",
    "\n",
    "def hbit(n: int) -> int:\n",
    "    return int(np.log2(n))\n",
    "\n",
    "\n",
    "\n",
    "def build_layers_down(inp_img_size: int = 256, inp_channels: int = 6, batch_size: Optional[int] = None) -> Tuple[Any, Any]:\n",
    "    assert is_pow_2(inp_img_size), f'input_size = {inp_img_size} is not power of 2'\n",
    "    assert 32 <= inp_img_size <= 512\n",
    "    nbits_in = hbit(inp_img_size)\n",
    "    input_shape = inp_img_size, inp_img_size, inp_channels\n",
    "    inp = tf.keras.Input(input_shape, batch_size=batch_size, dtype=tf.float32)\n",
    "\n",
    "# Basic scenario:\n",
    "#    size  channels\n",
    "# 0   256         6\n",
    "# 1   128         8\n",
    "# 2    64        16\n",
    "# 3    32        32\n",
    "# 4    16        64\n",
    "# 5     8       128\n",
    "# 6     4       256\n",
    "# 7     2       512\n",
    "# 8     1      1024\n",
    "\n",
    "    ch, ker_sz, stride = 4, 5, 2\n",
    "    if nbits_in < 8:\n",
    "        ch *= 2**(8 - nbits_in)\n",
    "    elif nbits_in > 8:\n",
    "        ker_sz, stride = 7, 4\n",
    "\n",
    "    x = inp\n",
    "    while nbits_in > 1:\n",
    "        act = None if nbits_in == 1 else tf.nn.relu\n",
    "        x, ch = block_down(x, stride, ch, ch * 2, ker_sz, act)\n",
    "        nbits_in -= hbit(stride)\n",
    "        if nbits_in + hbit(ch) == 10:\n",
    "            ker_sz, stride = 5, 2\n",
    "        if nbits_in <= 4:\n",
    "            ker_sz = 3\n",
    "    ch *= 2\n",
    "    x = tf.keras.layers.Conv2D(ch, 2, 1, 'valid')(x)\n",
    "\n",
    "    out = tf.reshape(x, (-1, ch))\n",
    "\n",
    "    return inp, out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-02 22:39:15.011184: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 256, 256, 6), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\") KerasTensor(type_spec=TensorSpec(shape=(None, 1024), dtype=tf.float32, name=None), name='tf.reshape/Reshape:0', description=\"created by layer 'tf.reshape'\")\n"
     ]
    }
   ],
   "source": [
    "maps_inp, map_features = build_layers_down()\n",
    "print(maps_inp, map_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `maps_features`: N_components x Feature_dimension. Feature represents embedding extracted by\n",
    "# backbone CNN from object's maps.\n",
    "# `graph_pts`: N_points_in_one_level x 3. Contains set of points distributed on sphere which represents\n",
    "# one level of vertices in the graph.\n",
    "# `n_verts` = N_points_in_one_level * `n_levels`. Number of vertices in the graph.\n",
    "# `n_levels` - number of descrete steps of interval: [0, pi), i.e. given h = pi / `n_levels`,\n",
    "# levels (0, 1, ..., `n_levels` - 1) correspond to values (0, h, ..., (`n_levels` - 1) * h) respectively.\n",
    "# `edges_dir`: N_components x N_directed_edges. Directed edges of graph with `n_verts` vertices.\n",
    "# `batch_size` = N_components.\n",
    "# `inp_pose_size` - Size of pose parameters vector needed to restore 3d position of object' center.\n",
    "def build_graph_head(maps_features: Any, graph_pts: np.ndarray, n_verts: int, n_levels: int, edges_dir: np.ndarray, batch_size: int, inp_pose_size: int = 6):\n",
    "    inp_pose = tf.keras.Input((inp_pose_size,), batch_size=batch_size, dtype=tf.float32)\n",
    "\n",
    "    n_pts, n_edges_dir = len(graph_pts), len(edges_dir)\n",
    "    pts = tf.convert_to_tensor(graph_pts, dtype=tf.float32)\n",
    "    edges_1 = tf.convert_to_tensor(edges_dir, dtype=tf.int64)\n",
    "    edges_2 = tf.reverse(edges_1, [1])\n",
    "    edges = tf.concat([edges_1, edges_2], axis=0)\n",
    "    n_edges = n_edges_dir * 2\n",
    "    edges = tf.tile(edges, (batch_size, 1))\n",
    "    shift = tf.range(0, batch_size * n_edges, n_edges, dtype=tf.int64)\n",
    "    shift = tf.repeat(shift, n_edges)[..., tf.newaxis]\n",
    "    edges += shift\n",
    "\n",
    "    angle_step = np.pi / n_levels\n",
    "    angles = tf.range(n_levels, dtype=tf.float32) * angle_step\n",
    "    angles = tf.reshape(angles, (n_levels, 1))\n",
    "\n",
    "    # batch_size x Feature_dimension --> batch_size * n_verts x Feature_dimension\n",
    "    vert_feat_maps = tf.repeat(maps_features, n_verts, axis=0)\n",
    "\n",
    "    # N_points_in_one_level x 3 --> n_verts x 3\n",
    "    vert_feat_pts = tf.tile(pts, (n_levels, 1))\n",
    "    # n_verts x 3 --> batch_size * n_verts x 3\n",
    "    vert_feat_pts = tf.tile(vert_feat_pts, (batch_size, 1))\n",
    "\n",
    "    # n_levels x 1 --> n_verts x 1\n",
    "    vert_feat_angle = tf.repeat(angles, n_pts, axis=0)\n",
    "    # n_verts x 1 --> batch_size * n_verts x 1\n",
    "    vert_feat_angle = tf.tile(vert_feat_angle, (batch_size, 1))\n",
    "\n",
    "    # batch_size x inp_pose_size --> batch_size * n_verts x inp_pose_size\n",
    "    vert_feat_pose = tf.repeat(inp_pose, n_verts, axis=0)\n",
    "\n",
    "    # batch_size * n_verts x (Feature_dimension + 3 + 1 + inp_pose_size)\n",
    "    vert_feat = tf.concat([vert_feat_maps, vert_feat_pts, vert_feat_angle, vert_feat_pose], axis=1)\n",
    "    vert_feat = tf.convert_to_tensor(vert_feat)\n",
    "    print(vert_feat.shape)\n",
    "\n",
    "\n",
    "    graph = tfgnn.GraphTensor.from_pieces(\n",
    "        context=tfgnn.Context.from_fields(\n",
    "            features={}\n",
    "        ),\n",
    "        node_sets={\n",
    "            tfgnn.NODES: tfgnn.NodeSet.from_fields(\n",
    "                sizes=tf.constant([n_verts] * batch_size),\n",
    "                features={\n",
    "                    tfgnn.HIDDEN_STATE: vert_feat,\n",
    "                },\n",
    "            ),\n",
    "        },\n",
    "        edge_sets={\n",
    "            tfgnn.EDGES: tfgnn.EdgeSet.from_fields(\n",
    "                sizes=tf.constant([len(edges)] * batch_size),\n",
    "                adjacency=tfgnn.Adjacency.from_indices(\n",
    "                    source=(tfgnn.NODES, edges[:, 0]),\n",
    "                    target=(tfgnn.NODES, edges[:, 1]),\n",
    "                ),\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(graph)\n",
    "\n",
    "    # graph = tfgnn.keras.layers.NodeSetUpdate(\n",
    "    #     next_state=tfgnn.keras.layers.NextStateFromConcat(tf.keras.layers.Dense(128)),\n",
    "    #     context_input_feature=['map_features', 'inp_pose', 'angles', 'pts'],\n",
    "    # )(graph)\n",
    "\n",
    "    # graph = GCNHomGraphUpdate(units=128, add_self_loops=True)(graph)\n",
    "    # graph = GCNHomGraphUpdate(units=128, add_self_loops=True)(graph)\n",
    "    # graph = GCNHomGraphUpdate(units=64, add_self_loops=True)(graph)\n",
    "    # graph = GCNHomGraphUpdate(units=64, add_self_loops=True)(graph)\n",
    "\n",
    "    # return inp_pose, graph\n",
    "    \n",
    "    return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pts = 1000\n",
    "n_levels = 100\n",
    "pts, n_verts, edges = calc_3d_graph_elevated(n_pts, n_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_img_size = 256\n",
    "inp_channels = 6\n",
    "batch_size = 10\n",
    "img_inp, features = build_layers_down(inp_img_size, inp_channels, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_graph_head' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m inp_pose_size \u001b[39m=\u001b[39m \u001b[39m6\u001b[39m\n\u001b[0;32m----> 2\u001b[0m inp_pose, graph \u001b[39m=\u001b[39m build_graph_head(features, pts, n_verts, n_levels, edges, batch_size, inp_pose_size)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'build_graph_head' is not defined"
     ]
    }
   ],
   "source": [
    "inp_pose_size = 6\n",
    "inp_pose, graph = build_graph_head(features, pts, n_verts, n_levels, edges, batch_size, inp_pose_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GcnLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, A: tf.sparse.SparseTensor, batch_size: int, n_verts: int, units: int, normalize: bool = True, add_self_loops: bool = True):\n",
    "        super().__init__()\n",
    "        self.A = A\n",
    "        self.batch_size = batch_size\n",
    "        self.n_verts = n_verts\n",
    "        self.units = units\n",
    "        self.normalize = normalize\n",
    "        self.add_self_loops = add_self_loops\n",
    "    \n",
    "    def call(self, features: Any):\n",
    "        normalized_values = features\n",
    "        normalized_values = tf.reshape(normalized_values, (self.batch_size * self.n_verts, features.shape[-1]))\n",
    "        invsqrt_deg = tf.constant([])\n",
    "        if self.normalize:\n",
    "            in_degree = tf.sparse.reduce_sum(self.A, axis=-1)\n",
    "            \n",
    "            if self.add_self_loops:\n",
    "                in_degree += 1\n",
    "            \n",
    "            invsqrt_deg = tf.math.rsqrt(in_degree)\n",
    "            normalized_values = invsqrt_deg[:, tf.newaxis] * features\n",
    "\n",
    "        print(tf.shape(self.A), tf.shape(normalized_values))\n",
    "        pooled = tf.sparse.sparse_dense_matmul(self.A, normalized_values)\n",
    "\n",
    "        if self.add_self_loops:\n",
    "            if self.normalize:\n",
    "                pooled += invsqrt_deg[:, tf.newaxis] * normalized_values\n",
    "            else:\n",
    "                pooled += normalized_values\n",
    "\n",
    "        # pooled = tf.reshape(pooled, (self.batch_size, self.n_verts, -1))\n",
    "        out = tf.keras.layers.Dense(units=self.units, activation='relu', use_bias=False)(pooled)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `maps_features`: N_components x Feature_dimension. Feature represents embedding extracted by\n",
    "# backbone CNN from object's maps.\n",
    "# `graph_pts`: N_points_in_one_level x 3. Contains set of points distributed on sphere which represents\n",
    "# one level of vertices in the graph.\n",
    "# `n_verts` = N_points_in_one_level * `n_levels`. Number of vertices in the graph.\n",
    "# `n_levels` - number of descrete steps of interval: [0, pi), i.e. given h = pi / `n_levels`,\n",
    "# levels (0, 1, ..., `n_levels` - 1) correspond to values (0, h, ..., (`n_levels` - 1) * h) respectively.\n",
    "# `edges_dir`: N_components x N_directed_edges. Directed edges of graph with `n_verts` vertices.\n",
    "# `batch_size` = N_components.\n",
    "# `inp_pose_size` - Size of pose parameters vector needed to restore 3d position of object' center.\n",
    "def build_head_manual(maps_features: Any, graph_pts: np.ndarray, n_verts: int, n_levels: int, edges_dir: np.ndarray, batch_size: int, inp_pose_size: int = 6,\n",
    "        normalize: bool = True, add_self_loops: bool = True):\n",
    "    inp_pose = tf.keras.Input((inp_pose_size,), batch_size=batch_size, dtype=tf.float32)\n",
    "    vert_pts = tf.convert_to_tensor(graph_pts, dtype=tf.float32)\n",
    "    \n",
    "    # Build adjacency matrix\n",
    "    n_edges_dir = len(edges_dir)\n",
    "    n_edges = n_edges_dir * 2\n",
    "    edges_1 = tf.convert_to_tensor(edges_dir, dtype=tf.int64)\n",
    "    edges_2 = tf.reverse(edges_1, axis=[1])\n",
    "    edges = tf.concat([edges_1, edges_2], axis=0)\n",
    "    edges = tf.tile(edges, (batch_size, 1))\n",
    "    shift = tf.range(0, batch_size * n_edges, n_edges, dtype=tf.int64)\n",
    "    shift = tf.repeat(shift, n_edges)[..., tf.newaxis]\n",
    "    edges += shift\n",
    "\n",
    "    A = tf.sparse.SparseTensor(edges, tf.ones(batch_size * n_edges, tf.float32), (batch_size * n_verts, batch_size * n_verts))\n",
    "    A = tf.sparse.reorder(A)\n",
    "\n",
    "    angle_step = np.pi / n_levels\n",
    "    angles = tf.range(n_levels, dtype=tf.float32) * angle_step\n",
    "    angles = tf.reshape(angles, (n_levels, 1))\n",
    "\n",
    "    # batch_size x Feature_dimension --> batch_size * n_verts x Feature_dimension\n",
    "    vert_feat_maps = tf.repeat(maps_features, n_verts, axis=0)\n",
    "\n",
    "    # n_verts x 3 --> batch_size * n_verts x 3\n",
    "    vert_feat_pts = tf.tile(vert_pts, (batch_size, 1))\n",
    "\n",
    "    # n_levels x 1 --> n_verts x 1\n",
    "    vert_feat_angle = tf.repeat(angles, n_pts, axis=0)\n",
    "    # n_verts x 1 --> batch_size * n_verts x 1\n",
    "    vert_feat_angle = tf.tile(vert_feat_angle, (batch_size, 1))\n",
    "\n",
    "    # batch_size x inp_pose_size --> batch_size * n_verts x inp_pose_size\n",
    "    vert_feat_pose = tf.repeat(inp_pose, n_verts, axis=0)\n",
    "\n",
    "    # batch_size * n_verts x (Feature_dimension + 3 + 1 + inp_pose_size)\n",
    "    vert_feat = tf.concat([vert_feat_maps, vert_feat_pts, vert_feat_angle, vert_feat_pose], axis=1)\n",
    "    vert_feat = tf.convert_to_tensor(vert_feat)\n",
    "    print(vert_feat.shape)\n",
    "\n",
    "    x = vert_feat\n",
    "    x = GcnLayer(A, batch_size, n_verts, 128, normalize, add_self_loops)(x)\n",
    "    x = GcnLayer(A, batch_size, n_verts, 128, normalize, add_self_loops)(x)\n",
    "    x = GcnLayer(A, batch_size, n_verts, 64, normalize, add_self_loops)(x)\n",
    "    x = GcnLayer(A, batch_size, n_verts, 32, normalize, add_self_loops)(x)\n",
    "    x = GcnLayer(A, batch_size, n_verts, 16, normalize, add_self_loops)(x)\n",
    "    x_pos = x\n",
    "\n",
    "    x = GcnLayer(A, batch_size, n_verts, 8, normalize, add_self_loops)(x)\n",
    "    x = GcnLayer(A, batch_size, n_verts, 1, normalize, add_self_loops)(x)\n",
    "    out_rot = x\n",
    "\n",
    "    x = x_pos\n",
    "    x = tf.keras.layers.Dense(16, 'relu', use_bias=True)(x)\n",
    "    x = tf.keras.layers.Dense(16, 'relu', use_bias=True)(x)\n",
    "    x = tf.reshape(x, (batch_size, n_verts, 16))\n",
    "    x = tf.reduce_mean(x, axis=1)\n",
    "    x = tf.keras.layers.Dense(16, 'relu', use_bias=True)(x)\n",
    "    x = tf.keras.layers.Dense(16, 'relu', use_bias=True)(x)\n",
    "    x = tf.keras.layers.Dense(3, 'relu', use_bias=True)(x)\n",
    "    out_pos = x\n",
    "\n",
    "    return inp_pose, out_pos, out_rot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 1034)\n",
      "reduce_sum Tensor(\"gcn_layer_9/Shape/Cast:0\", shape=(2,), dtype=int32)\n",
      "!!! reduced !!!\n",
      "Tensor(\"gcn_layer_9/Shape_1/Cast:0\", shape=(2,), dtype=int32) Tensor(\"gcn_layer_9/Shape_2:0\", shape=(2,), dtype=int32)\n",
      "!!! done !!!\n",
      "make_gcn_layer (1000000, 128)\n",
      "reduce_sum Tensor(\"gcn_layer_10/Shape/Cast:0\", shape=(2,), dtype=int32)\n",
      "!!! reduced !!!\n",
      "Tensor(\"gcn_layer_10/Shape_1/Cast:0\", shape=(2,), dtype=int32) Tensor(\"gcn_layer_10/Shape_2:0\", shape=(2,), dtype=int32)\n",
      "!!! done !!!\n",
      "make_gcn_layer (1000000, 128)\n",
      "reduce_sum Tensor(\"gcn_layer_11/Shape/Cast:0\", shape=(2,), dtype=int32)\n",
      "!!! reduced !!!\n",
      "Tensor(\"gcn_layer_11/Shape_1/Cast:0\", shape=(2,), dtype=int32) Tensor(\"gcn_layer_11/Shape_2:0\", shape=(2,), dtype=int32)\n",
      "!!! done !!!\n",
      "make_gcn_layer (1000000, 64)\n",
      "reduce_sum Tensor(\"gcn_layer_12/Shape/Cast:0\", shape=(2,), dtype=int32)\n",
      "!!! reduced !!!\n",
      "Tensor(\"gcn_layer_12/Shape_1/Cast:0\", shape=(2,), dtype=int32) Tensor(\"gcn_layer_12/Shape_2:0\", shape=(2,), dtype=int32)\n",
      "!!! done !!!\n",
      "make_gcn_layer (1000000, 32)\n",
      "reduce_sum Tensor(\"gcn_layer_13/Shape/Cast:0\", shape=(2,), dtype=int32)\n",
      "!!! reduced !!!\n",
      "Tensor(\"gcn_layer_13/Shape_1/Cast:0\", shape=(2,), dtype=int32) Tensor(\"gcn_layer_13/Shape_2:0\", shape=(2,), dtype=int32)\n",
      "!!! done !!!\n",
      "make_gcn_layer (1000000, 16)\n",
      "reduce_sum Tensor(\"gcn_layer_14/Shape/Cast:0\", shape=(2,), dtype=int32)\n",
      "!!! reduced !!!\n",
      "Tensor(\"gcn_layer_14/Shape_1/Cast:0\", shape=(2,), dtype=int32) Tensor(\"gcn_layer_14/Shape_2:0\", shape=(2,), dtype=int32)\n",
      "!!! done !!!\n",
      "make_gcn_layer (1000000, 8)\n",
      "reduce_sum Tensor(\"gcn_layer_15/Shape/Cast:0\", shape=(2,), dtype=int32)\n",
      "!!! reduced !!!\n",
      "Tensor(\"gcn_layer_15/Shape_1/Cast:0\", shape=(2,), dtype=int32) Tensor(\"gcn_layer_15/Shape_2:0\", shape=(2,), dtype=int32)\n",
      "!!! done !!!\n",
      "make_gcn_layer (1000000, 1)\n"
     ]
    }
   ],
   "source": [
    "inp_pose_size = 6\n",
    "inp_pose, out_pos, out_rot = build_head_manual(features, pts, n_verts, n_levels, edges, batch_size, inp_pose_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.get_value(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = tf.keras.backend\n",
    "K.eager(K.get_value)(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.eval(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.fill(5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.ones(5, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 0 2]\n",
      " [0 0 3]\n",
      " [0 2 3]\n",
      " [0 4 2]\n",
      " [0 4 3]], shape=(5, 3), dtype=int64), values=tf.Tensor([1. 1. 1. 1. 1.], shape=(5,), dtype=float32), dense_shape=tf.Tensor([1 5 5], shape=(3,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "A = tf.sparse.SparseTensor([[0, 0, 2], [0, 0, 3], [0, 2, 3], [0, 4, 3], [0, 4, 2]], [1.0, 1., 1., 1., 1.], (1, 5, 5))\n",
    "A = tf.sparse.reorder(A)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0. 0. 2. 3. 0.]], shape=(1, 5), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[1., 1., 3., 4., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x: tf.Tensor = tf.sparse.reduce_sum(A, axis=1)\n",
    "print(x)\n",
    "x += 1\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 2), dtype=float32, numpy=\n",
       "array([[[ 1.,  2.],\n",
       "        [ 3.,  4.],\n",
       "        [ 5.,  6.]],\n",
       "\n",
       "       [[ 7.,  8.],\n",
       "        [ 9., 10.],\n",
       "        [11., 12.]]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[1.0, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12]])\n",
    "x = tf.reshape(x, (2, 3, 2))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__SparseTensorDenseMatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Tensor 'b' is not a matrix [Op:SparseTensorDenseMatMul]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tf\u001b[39m.\u001b[39;49msparse\u001b[39m.\u001b[39;49msparse_dense_matmul(A, x)\n",
      "File \u001b[0;32m~/miniconda3/envs/sds/lib/python3.9/site-packages/tensorflow/python/ops/sparse_ops.py:2644\u001b[0m, in \u001b[0;36msparse_tensor_dense_matmul\u001b[0;34m(sp_a, b, adjoint_a, adjoint_b, name)\u001b[0m\n\u001b[1;32m   2641\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(name, \u001b[39m\"\u001b[39m\u001b[39mSparseTensorDenseMatMul\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2642\u001b[0m                     [sp_a\u001b[39m.\u001b[39mindices, sp_a\u001b[39m.\u001b[39mvalues, b]) \u001b[39mas\u001b[39;00m name:\n\u001b[1;32m   2643\u001b[0m   b \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(b, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2644\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_sparse_ops\u001b[39m.\u001b[39;49msparse_tensor_dense_mat_mul(\n\u001b[1;32m   2645\u001b[0m       a_indices\u001b[39m=\u001b[39;49msp_a\u001b[39m.\u001b[39;49mindices,\n\u001b[1;32m   2646\u001b[0m       a_values\u001b[39m=\u001b[39;49msp_a\u001b[39m.\u001b[39;49mvalues,\n\u001b[1;32m   2647\u001b[0m       a_shape\u001b[39m=\u001b[39;49msp_a\u001b[39m.\u001b[39;49mdense_shape,\n\u001b[1;32m   2648\u001b[0m       b\u001b[39m=\u001b[39;49mb,\n\u001b[1;32m   2649\u001b[0m       adjoint_a\u001b[39m=\u001b[39;49madjoint_a,\n\u001b[1;32m   2650\u001b[0m       adjoint_b\u001b[39m=\u001b[39;49madjoint_b)\n",
      "File \u001b[0;32m~/miniconda3/envs/sds/lib/python3.9/site-packages/tensorflow/python/ops/gen_sparse_ops.py:3051\u001b[0m, in \u001b[0;36msparse_tensor_dense_mat_mul\u001b[0;34m(a_indices, a_values, a_shape, b, adjoint_a, adjoint_b, name)\u001b[0m\n\u001b[1;32m   3049\u001b[0m   \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   3050\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 3051\u001b[0m   _ops\u001b[39m.\u001b[39;49mraise_from_not_ok_status(e, name)\n\u001b[1;32m   3052\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_FallbackException:\n\u001b[1;32m   3053\u001b[0m   \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/sds/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7207\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7208\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 7209\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__SparseTensorDenseMatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Tensor 'b' is not a matrix [Op:SparseTensorDenseMatMul]"
     ]
    }
   ],
   "source": [
    "tf.sparse.sparse_dense_matmul(A, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\n",
       "array([[[6, 3, 0],\n",
       "        [8, 6, 7]],\n",
       "\n",
       "       [[8, 3, 0],\n",
       "        [9, 7, 1]]], dtype=int32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform((2, 2, 3), 0, 10, dtype=tf.int32)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 6), dtype=int32, numpy=\n",
       "array([[6, 3, 0, 8, 6, 7],\n",
       "       [8, 3, 0, 9, 7, 1]], dtype=int32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(x, (2, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[8, 3, 0],\n",
       "       [9, 7, 1]], dtype=int32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "input = tf.random.normal(shape=(3, 12))\n",
    "k = 2\n",
    "values, indices  = tf.math.top_k(input, k=k)\n",
    "print(values.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 12), dtype=float32, numpy=\n",
       "array([[ 0.3277132 , -0.08097047, -1.4443549 , -0.37999842, -0.51421654,\n",
       "        -1.3463523 ,  1.169286  ,  0.40608847, -1.3081495 , -0.17982765,\n",
       "         2.1462622 , -1.832191  ],\n",
       "       [-0.5616635 , -0.8308778 ,  0.07133581,  0.22717148, -0.49391243,\n",
       "        -0.83485305, -0.14846714,  1.1375853 , -1.4950925 ,  0.72516304,\n",
       "         0.3868215 , -1.0906208 ],\n",
       "       [-1.3250701 , -1.0344608 ,  1.29745   , -1.3784496 , -0.6767564 ,\n",
       "        -0.16289645,  0.24838132,  0.23087345,  0.79717726, -1.4853148 ,\n",
       "         0.42025313, -0.39925814]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[2.1462622 , 1.169286  ],\n",
       "       [1.1375853 , 0.72516304],\n",
       "       [1.29745   , 0.79717726]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[10,  6],\n",
       "       [ 7,  9],\n",
       "       [ 2,  8]], dtype=int32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\n",
       "array([[[6, 3, 0],\n",
       "        [8, 6, 7]],\n",
       "\n",
       "       [[8, 3, 0],\n",
       "        [9, 7, 1]]], dtype=int32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n",
       "array([[[6, 3],\n",
       "        [8, 6]],\n",
       "\n",
       "       [[8, 3],\n",
       "        [9, 7]]], dtype=int32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[..., :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('sds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "338a0ee46b080b016d6e25622ea4b78e5348bb1b1dbe27fb3bb412faa2e2f464"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
